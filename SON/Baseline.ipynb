{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Dependacies**"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import datasets,layers,models\n","import os\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["# **Importing Training Data**"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["ClassNames = ['Aircraft Carrier', 'Bulkers', 'Car Carrier', 'Container Ship', 'Cruise', 'DDG', 'Recreational', 'Sailboat', 'Submarine', 'Tug']"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 3] 지정된 경로를 찾을 수 없습니다: './Data/Ships_dataset/train/images'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m pathi \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_image)\n\u001b[0;32m      5\u001b[0m pathl \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_label)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathi\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      8\u001b[0m     file_p  \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pathi, file)\n\u001b[0;32m      9\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(file_p)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './Data/Ships_dataset/train/images'"]}],"source":["data_image = '/Data/Ships_dataset/train/images'\n","data_label = '/Data/Ships_dataset/train/labels'\n","traindata = []\n","pathi = os.path.join(data_image)\n","pathl = os.path.join(data_label)\n","\n","for file in os.listdir(pathi):\n","    file_p  = os.path.join(pathi, file)\n","    image = cv2.imread(file_p)\n","    image = np.array(image)\n","    image=cv2.resize(image, (64,64),interpolation=cv2.INTER_LINEAR)\n","    traindata.append(image)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainlabel = []\n","for file in os.listdir(pathl):\n","    file_p  = os.path.join(pathl, file)\n","    f = open(file_p, \"r\")\n","    a = int(f.read(1))\n","    trainlabel.append(a)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = []\n","for i in range(0,len(trainlabel)):\n","    traindata[i] = traindata[i]/255\n","    data.append((traindata[i], trainlabel[i]))\n","\n","random.shuffle(data)\n","images, labels =  [], []\n","for a, b in data:\n","    images.append(a)\n","    labels.append(b)\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["# **Visualize the Data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(16):\n","    plt.subplot(4,4,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.imshow(images[i],cmap=plt.cm.binary)\n","    plt.xlabel(ClassNames[labels[i]])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# **Importing Validation Data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_image = '/Data/Ships dataset/valid/images'\n","data_label = '/Data/Ships dataset/valid/labels'\n","validdata = []\n","pathi = os.path.join(data_image)\n","pathl = os.path.join(data_label)\n","\n","for file in os.listdir(pathi):\n","    file_p  = os.path.join(pathi, file)\n","    image = cv2.imread(file_p)\n","    image = np.array(image)\n","    image=cv2.resize(image, (64,64),interpolation=cv2.INTER_LINEAR)\n","    validdata.append(image)\n","    \n","validlabel = []\n","for file in os.listdir(pathl):\n","    file_p  = os.path.join(pathl, file)\n","    f = open(file_p, \"r\")\n","    a = int(f.read(1))\n","    validlabel.append(a)\n","    \n","validation = []\n","for i in range(0,len(validlabel)):\n","    validdata[i] = validdata[i]/255\n","    validation.append((validdata[i], validlabel[i]))\n","\n","random.shuffle(validation)\n","validationimages, validationlabels =  [], []\n","for a, b in validation:\n","    validationimages.append(a)\n","    validationlabels.append(b)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["images = np.array(images)\n","labels = np.array(labels)\n","validationimages = np.array(validationimages)\n","validationlabels = np.array(validationlabels)"]},{"cell_type":"markdown","metadata":{},"source":["# **Model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = models.Sequential()\n","model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(64,64,3)))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(128,(3,3),activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(128,(3,3),activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128,activation='relu'))\n","model.add(layers.Dense(64,activation='relu'))\n","model.add(layers.Dense(10,activation='softmax'))\n","\n","model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{},"source":["# **Training the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(images,labels,batch_size = 32,epochs=20,validation_data=(validationimages,validationlabels))\n","\n","loss, accuracy = model.evaluate(images,labels)\n","print(f\"Loss: {loss}\")\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"markdown","metadata":{},"source":["# **Exporing the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save('ShipClassifierV1.h5')"]},{"cell_type":"markdown","metadata":{},"source":["# **Loading the model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = models.load_model('ShipClassifierV1.h5')"]},{"cell_type":"markdown","metadata":{},"source":["# **Importing testing Data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_image = '/Data/Ships dataset/test/images'\n","data_label = '/Data/Ships dataset/test/labels'\n","testdata = []\n","pathi = os.path.join(data_image)\n","pathl = os.path.join(data_label)\n","\n","for file in os.listdir(pathi):\n","    file_p  = os.path.join(pathi, file)\n","    image = cv2.imread(file_p)\n","    image = np.array(image)\n","    image=cv2.resize(image, (64,64),interpolation=cv2.INTER_LINEAR)\n","    testdata.append(image)\n","    \n","testlabel = []\n","for file in os.listdir(pathl):\n","    file_p  = os.path.join(pathl, file)\n","    f = open(file_p, \"r\")\n","    a = int(f.read(1))\n","    testlabel.append(a)\n","    \n","testing = []\n","for i in range(0,len(testlabel)):\n","    testdata[i] = testdata[i]/255\n","    testing.append((testdata[i], testlabel[i]))\n","\n","random.shuffle(testing)\n","testingimages, testinglabels =  [], []\n","for a, b in testing:\n","    testingimages.append(a)\n","    testinglabels.append(b)\n","    \n","testinglabels = np.array(testinglabels)\n","testingimages = np.array(testingimages)"]},{"cell_type":"markdown","metadata":{},"source":["# **Testing the model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, accuracy = model.evaluate(testingimages,testinglabels)\n","print(f\"Loss: {loss}\")\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(4):\n","    plt.subplot(2,2,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.imshow(testingimages[i],cmap=plt.cm.binary)\n","    pred = model.predict(np.array([testingimages[i]]))\n","    index = np.argmax(pred)\n","    plt.xlabel(f\"Actual = {ClassNames[testinglabels[i]]} \\n Predicted = {ClassNames[index]}\")\n","    \n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2331073,"sourceId":3926270,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
