{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3926270,"sourceType":"datasetVersion","datasetId":2331073}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Dependacies**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import datasets,layers,models\nimport os\nimport random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing Training Data**","metadata":{}},{"cell_type":"code","source":"ClassNames = ['Aircraft Carrier', 'Bulkers', 'Car Carrier', 'Container Ship', 'Cruise', 'DDG', 'Recreational', 'Sailboat', 'Submarine', 'Tug']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_image = '/kaggle/input/ships-dataset/Ships dataset/train/images'\ndata_label = '/kaggle/input/ships-dataset/Ships dataset/train/labels'\ntraindata = []\npathi = os.path.join(data_image)\npathl = os.path.join(data_label)\n\nfor file in os.listdir(pathi):\n    file_p  = os.path.join(pathi, file)\n    image = cv2.imread(file_p)\n    image = np.array(image)\n    image=cv2.resize(image, (64,64),interpolation=cv2.INTER_LINEAR)\n    traindata.append(image)\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainlabel = []\nfor file in os.listdir(pathl):\n    file_p  = os.path.join(pathl, file)\n    f = open(file_p, \"r\")\n    a = int(f.read(1))\n    trainlabel.append(a)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nfor i in range(0,len(trainlabel)):\n    traindata[i] = traindata[i]/255\n    data.append((traindata[i], trainlabel[i]))\n\nrandom.shuffle(data)\nimages, labels =  [], []\nfor a, b in data:\n    images.append(a)\n    labels.append(b)\n    \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualize the Data**","metadata":{}},{"cell_type":"code","source":"for i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(images[i],cmap=plt.cm.binary)\n    plt.xlabel(ClassNames[labels[i]])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing Validation Data**","metadata":{}},{"cell_type":"code","source":"data_image = '/kaggle/input/ships-dataset/Ships dataset/valid/images'\ndata_label = '/kaggle/input/ships-dataset/Ships dataset/valid/labels'\nvaliddata = []\npathi = os.path.join(data_image)\npathl = os.path.join(data_label)\n\nfor file in os.listdir(pathi):\n    file_p  = os.path.join(pathi, file)\n    image = cv2.imread(file_p)\n    image = np.array(image)\n    image=cv2.resize(image, (64,64),interpolation=cv2.INTER_LINEAR)\n    validdata.append(image)\n    \nvalidlabel = []\nfor file in os.listdir(pathl):\n    file_p  = os.path.join(pathl, file)\n    f = open(file_p, \"r\")\n    a = int(f.read(1))\n    validlabel.append(a)\n    \nvalidation = []\nfor i in range(0,len(validlabel)):\n    validdata[i] = validdata[i]/255\n    validation.append((validdata[i], validlabel[i]))\n\nrandom.shuffle(validation)\nvalidationimages, validationlabels =  [], []\nfor a, b in validation:\n    validationimages.append(a)\n    validationlabels.append(b)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.array(images)\nlabels = np.array(labels)\nvalidationimages = np.array(validationimages)\nvalidationlabels = np.array(validationlabels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(64,64,3)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128,activation='relu'))\nmodel.add(layers.Dense(64,activation='relu'))\nmodel.add(layers.Dense(10,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training the Model**","metadata":{}},{"cell_type":"code","source":"model.fit(images,labels,batch_size = 32,epochs=20,validation_data=(validationimages,validationlabels))\n\nloss, accuracy = model.evaluate(images,labels)\nprint(f\"Loss: {loss}\")\nprint(f\"Accuracy: {accuracy}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exporing the Model**","metadata":{}},{"cell_type":"code","source":"model.save('ShipClassifierV1.h5')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading the model**","metadata":{}},{"cell_type":"code","source":"model = models.load_model('ShipClassifierV1.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing testing Data**","metadata":{}},{"cell_type":"code","source":"data_image = '/kaggle/input/ships-dataset/Ships dataset/test/images'\ndata_label = '/kaggle/input/ships-dataset/Ships dataset/test/labels'\ntestdata = []\npathi = os.path.join(data_image)\npathl = os.path.join(data_label)\n\nfor file in os.listdir(pathi):\n    file_p  = os.path.join(pathi, file)\n    image = cv2.imread(file_p)\n    image = np.array(image)\n    image=cv2.resize(image, (64,64),interpolation=cv2.INTER_LINEAR)\n    testdata.append(image)\n    \ntestlabel = []\nfor file in os.listdir(pathl):\n    file_p  = os.path.join(pathl, file)\n    f = open(file_p, \"r\")\n    a = int(f.read(1))\n    testlabel.append(a)\n    \ntesting = []\nfor i in range(0,len(testlabel)):\n    testdata[i] = testdata[i]/255\n    testing.append((testdata[i], testlabel[i]))\n\nrandom.shuffle(testing)\ntestingimages, testinglabels =  [], []\nfor a, b in testing:\n    testingimages.append(a)\n    testinglabels.append(b)\n    \ntestinglabels = np.array(testinglabels)\ntestingimages = np.array(testingimages)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Testing the model**","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(testingimages,testinglabels)\nprint(f\"Loss: {loss}\")\nprint(f\"Accuracy: {accuracy}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(4):\n    plt.subplot(2,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(testingimages[i],cmap=plt.cm.binary)\n    pred = model.predict(np.array([testingimages[i]]))\n    index = np.argmax(pred)\n    plt.xlabel(f\"Actual = {ClassNames[testinglabels[i]]} \\n Predicted = {ClassNames[index]}\")\n    \nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}